{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNNW_end2end_sub.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "airtwZNxnExX",
        "ByhLlT6g586I",
        "IdQ6bH0RDNsk",
        "R7Nbd2R0s9mS"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le7FDQiqznw4"
      },
      "source": [
        "## 1.1 Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-u9kDANznGE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63399e3b-fba6-48bc-c7c4-f2ec227355bb"
      },
      "source": [
        "!nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name, driver_version, memory.total [MiB]\n",
            "Tesla V100-SXM2-16GB, 460.32.03, 16160 MiB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFdDt-rcsL2H"
      },
      "source": [
        "## 1.2 Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyb_wJkysNxl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71374bb8-07e4-4029-85fd-34a3470b8f8c"
      },
      "source": [
        "# Connect Google drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "airtwZNxnExX"
      },
      "source": [
        "## 1.3 Import library and define global variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5KyGHthWyMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5003be9d-ce83-4e0b-a2eb-34b506dd1afa"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "!pip install num2words\n",
        "from num2words import num2words\n",
        "\n",
        "!pip install python-levenshtein\n",
        "import Levenshtein\n",
        "\n",
        "!pip install torch-summary\n",
        "import torchsummary\n",
        "\n",
        "!pip install torchaudio\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda, sys.version)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "device"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: num2words in /usr/local/lib/python3.7/dist-packages (0.5.10)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words) (0.6.2)\n",
            "Requirement already satisfied: python-levenshtein in /usr/local/lib/python3.7/dist-packages (0.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-levenshtein) (56.1.0)\n",
            "Requirement already satisfied: torch-summary in /usr/local/lib/python3.7/dist-packages (1.4.5)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n",
            "True 3.7.10 (default, May  3 2021, 02:48:31) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tu_Y72B4pzi"
      },
      "source": [
        "## 2.1 Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFhyGgbGn69W",
        "outputId": "74ac694b-5115-425c-d180-bdf3c9d9d57c"
      },
      "source": [
        "# Import code\n",
        "from constant import LETTER_LIST, LABEL_LIST\n",
        "from utils import *\n",
        "from preprocess import preprocess, get_letter_vocab\n",
        "from datasets import KnnwSpeechDataset, KnnwSpeakerDataset, KnnwDataset\n",
        "from speech_model import *\n",
        "from speaker_model import *\n",
        "from training import LASSession, SpeakerRecSession\n",
        "from training import thred_sched, LRSched_0arg, PlateauSched"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/IDL/Project\n",
            "/content/gdrive/.shortcut-targets-by-id/1nFHCtUbxTfWD0vW9CiANn58b6Rg7JhIt/11785Project/sessions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VN0ryDp6Zqc",
        "outputId": "4d43081e-50af-4aa4-ea85-1fc754ef7901"
      },
      "source": [
        "# Load data\n",
        "# DATA = path_to_data_files\n",
        "sub_data_path = os.path.join(DATA, \"knnw_en_sub_labeled.csv\")\n",
        "sub_df = pd.read_table(sub_data_path, sep = \";\", header=0)\n",
        "audio_path = os.path.join(DATA, \"log_spectrogram.npy\")\n",
        "audio_data = np.load(audio_path).transpose()\n",
        "\n",
        "print(sub_df.shape)\n",
        "print(audio_data.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1393, 5)\n",
            "(1370493, 129)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7Nbd2R0s9mS"
      },
      "source": [
        "## 2.2 Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOgfxzXl0day"
      },
      "source": [
        "processed_df = preprocess(sub_df, remove_music=True)\n",
        "\n",
        "print(\"Letter vocab:\", get_letter_vocab(processed_df[\"Processed Text\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWNDT07a8qiE"
      },
      "source": [
        "def get_loaders(dataset, audio_data, transcript_df, batch_size=32, split=0.15, seed=None):\n",
        "    train_df, test_df = random_split(transcript_df, split, seed)\n",
        "    train_set = dataset(audio_data, train_df, total_frames=len(audio_data))\n",
        "    test_set = dataset(audio_data, test_df, total_frames=len(audio_data))\n",
        "    train_loader = DataLoader(train_set, batch_size, shuffle=True, collate_fn=dataset.collate)\n",
        "    test_loader = DataLoader(test_set, batch_size, shuffle=False, collate_fn=dataset.collate)\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIs4AFl3-mye"
      },
      "source": [
        "## Speech Recognition Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi3si1NY-laU"
      },
      "source": [
        "def transfer_encoder_lstm(model):\n",
        "    model.encoder.lstm = nn.LSTM(input_size=129, hidden_size=256, num_layers=2, dropout=0.3,\n",
        "                            bidirectional=True, batch_first=True).to(device)\n",
        "    return model.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5TkXkGk-O53",
        "outputId": "623d9498-24af-4334-fb00-e35a978f81b1"
      },
      "source": [
        "train_loader, test_loader = get_loaders(KnnwSpeechDataset, audio_data, processed_df, batch_size=32, split=0.15)\n",
        "speech_session = LASSession('sessions/speech_session',\n",
        "                            lambda: transfer_encoder_lstm(LASSession('hw4p2').load_checkpoint(\"best\").model), # Transfer from existing HW4p2 model   \n",
        "                            lambda m: torch.optim.AdamW(m.parameters(), lr=1e-4),\n",
        "                            nn.CrossEntropyLoss(reduction='none'),\n",
        "                            train_data=train_loader,\n",
        "                            val_data=test_loader,\n",
        "                            use_amp=False,\n",
        "                            sched_factory=LRSched_0arg(\n",
        "                                lambda op:\n",
        "                                optim.lr_scheduler.MultiStepLR(op, [250, 350, 450, 550], 0.5, verbose=True)),\n",
        "                            tf_sched=lambda e: thred_sched(e, 300, 0.001, init=0.9, minval=0.7),\n",
        "                            af_sched=lambda e: thred_sched(e, 80, 0.05, init=1, minval=0)\n",
        ")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded checkpoint hw4p2/last\n",
            "Restored to epoch 78\n",
            "Loaded checkpoint hw4p2/best\n",
            "Adjusting learning rate of group 0 to 1.0000e-04.\n",
            "Checkpoint sessions/speech_session/last doesn't exist.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnSmq2fDAUY6"
      },
      "source": [
        "# Train for 600 epochs\n",
        "speech_session.train(600)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP81r4mEAXer"
      },
      "source": [
        "## Speaker Identification Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKZ3xG8kBZw1"
      },
      "source": [
        "train_loader, test_loader = get_loaders(KnnwSpeakerDataset, audio_data, processed_df, batch_size=32, split=0.15)\n",
        "speaker_session = SpeakerRecSession('sessions/speaker_session',\n",
        "                    lambda: SpeakerNet1d([256, 256], lstm_hidden=256, lstm_layers=3, dropout=0.5, \n",
        "                                         num_classes=len(LABEL_LIST)).to(device),\n",
        "                    lambda m: torch.optim.AdamW(m.parameters(), lr=5e-4),\n",
        "                    nn.CrossEntropyLoss(),\n",
        "                    train_data=train_loader,\n",
        "                    val_data=test_loader,\n",
        "                    use_amp=False,\n",
        "                    sched_factory=lambda op: \n",
        "                        PlateauSched(op, 'loss', factor=0.5, patience=2, cooldown=1, min_lr=1e-6, verbose=True)\n",
        "                    )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIRAubBXB2p3"
      },
      "source": [
        "# Train for 100 epochs\n",
        "speaker_session.train(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz22ToOj6h4J"
      },
      "source": [
        "## End-to-End Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0wmomayuQ0k"
      },
      "source": [
        "def batch_infer(speech_model, speaker_model, x, xlens):\n",
        "    results = []\n",
        "    x = x.to(device)\n",
        "    speech_predictions = speech_model(x, xlens)\n",
        "    decoded = batch_decode(speech_predictions)\n",
        "    speaker_pred = speaker_model(x, xlens)\n",
        "    speaker_pred = torch.argmax(speaker_pred, 1)\n",
        "    for i in range(len(speaker_pred)):\n",
        "        lab = index2label[speaker_pred[i].item()]\n",
        "        line = ''\n",
        "        if lab != 'None':\n",
        "            line = f'[{lab}] '\n",
        "        line += decoded[i]\n",
        "        results.append(line)\n",
        "    return results\n",
        "\n",
        "def end2end(speech_model, speaker_model, data):\n",
        "    result = []\n",
        "    total_time = 0\n",
        "    for x, y, xl, yl, labs in data:\n",
        "        st = time.time()\n",
        "        result += batch_infer(speech_model, speaker_model, x, xl)\n",
        "        btime = time.time() - st\n",
        "        total_time += btime\n",
        "    return result, total_time/len(data.dataset)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQxn2NykyxvG"
      },
      "source": [
        "_, test_loader = get_loaders(KnnwDataset, audio_data, processed_df)\n",
        "\n",
        "speech_model = speech_session.model.eval()\n",
        "speaker_model = speaker_session.model.eval()\n",
        "\n",
        "results, avg_time = end2end(speech_model, speaker_model, test_loader)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SUXH5FP1Enx",
        "outputId": "f9912cf7-c876-4c86-f2a1-a974991f2852"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['taki a look of the broadcast evacuation went up',\n",
              " '[Okudera] ah',\n",
              " \"how'd terry us stared norrn stuff not sense\",\n",
              " \"[Teshi] i'll go no lonker whole town less\",\n",
              " \"[Yotsuha] i cest that's way it\",\n",
              " \"[Mitsuha] the eyetochooo ya said she's eatin'\",\n",
              " '[Taki] ha mitsuha',\n",
              " '[Mitsuha] oucu make us',\n",
              " '[Taki] i stokped today threazy of sounds up broadcast about a wreazy',\n",
              " '[Taki] taki huh yea the election person',\n",
              " '[Taki+Okudera] no i thousand deftine bayazane was',\n",
              " 'i wanna grant a ready what do touract his residents it was totally too',\n",
              " '[Radio] yeah of your relic',\n",
              " \"[Taki] do you wait't thos pansay\",\n",
              " '[Mitsuha] would i bottle great i maiden',\n",
              " \"[Mitsuha] gid it's do it\",\n",
              " '[Taki] huh',\n",
              " \"[Mitsuha+Teshi] seek you're found out something\",\n",
              " '[Okudera] you were gond stone i your uncredty going to like',\n",
              " '[Yotsuha] what is she like its',\n",
              " \"[Mitsuha] and he couldn't it\",\n",
              " '[Mitsuha] who are you',\n",
              " \"today tou can to cactore charge of the stack here worth the spittin'\",\n",
              " \"[Mitsuha] what that's where it's not that the earth are coming it\",\n",
              " '[Teshi] the warning system come on the speckles of the town',\n",
              " '[Taki] one of her ne',\n",
              " '[Taki] someone',\n",
              " '[Okudera] does remain well',\n",
              " 'we have to tave that your everyone in town before today nine shouh out',\n",
              " \"[Okudera] i don't do it according to the minute but still\",\n",
              " \"[Sara] maybe it's for struck a unho you ve gotta rich work on tsuka\",\n",
              " '[Taki] shrine mitsuha',\n",
              " \"[Grandma] that's the miyamizu shrine gotsa far an promint of tess\",\n",
              " \"[Saya] katsuhikama fare to see me one you could 'cause of anciently\",\n",
              " \"but if it should' fragment on so you free lost of\",\n",
              " '[Taki] mitsuha runk yes area',\n",
              " 'so that taki you seeya hey',\n",
              " '[Taki] gid now marked',\n",
              " '[Taki] and you wake',\n",
              " '[Taki] gray uh yes',\n",
              " '[Taki] uh well i gotta be met uuhard julie',\n",
              " '[Mitsuha] what what outside the disaste jare is you',\n",
              " \"[Taki] you're named\",\n",
              " '[TV] over the cores of the last change the cheshiment comet miyamizu butt wait people seeya',\n",
              " 'shr dad asked be a week it',\n",
              " '[Taki] mitsuha',\n",
              " \"[Yotsuha] a templs of side somestin' of the town's\",\n",
              " '[Taki] whold them',\n",
              " 'katsuhin you are you hear he says a net ready no was dear',\n",
              " \"[Grandma] it's onver te ye beeven a few or tomate for a relig man she's our states one roung\",\n",
              " '[Taki] ugh',\n",
              " '[Yotsuha] resides still huh',\n",
              " '[Taki] if it is true and time conbine beyond ravel',\n",
              " '[Taki] if the serious you must be sit',\n",
              " '[Mitsuha] who',\n",
              " '[Mitsuha] oh',\n",
              " '[Taki] but you should tell te a see the comet in the skill',\n",
              " \"but there's no way you could\",\n",
              " '[Taki] itomi you',\n",
              " '[Mitsuha] i feel i go get on so we for with someone with some reason',\n",
              " '[Taki] mitsuha what wan',\n",
              " '[Okudera] do you all ge out die who',\n",
              " \"[Taki] maybe you're so monttown you go hey on you\",\n",
              " \"[Taki] i i don't not\",\n",
              " \"[Taki] what's your name\",\n",
              " \"[Taki] i don't know what to sayara\",\n",
              " \"[Mitsuha] that's what i think happened to itomori gan\",\n",
              " \"[Sara] unrelic it on a relationship because i don't want a look\",\n",
              " '[Taki] wh',\n",
              " '[Mitsuha] uh',\n",
              " '[Yotsuha] an hahaha',\n",
              " \"[Saya+Teshi] what you are procker's comet\",\n",
              " '[Taki] what a strange dream',\n",
              " '[Yotsuha] who worked hom',\n",
              " \"[Mitsuha] i shouldn't fad hurrs\",\n",
              " '[Taki] but the way i wanted the think you fill her hepped that customer already',\n",
              " '[Mitsuha] taki',\n",
              " \"[Saya] it won't hum\",\n",
              " \"[Taki] that's but i remember\",\n",
              " \"[Sara] well i see machind war them you're doing\",\n",
              " \"it's only when are strange stoxes ere the two hundred yeah\",\n",
              " '[Mitsuha] what is miyamizu hat the taka wanna bad out why',\n",
              " \"[Mitsuha] i can't can't\",\n",
              " '[Taki] wha',\n",
              " \"[Taki] what is locan get in and i chanted he'll so i tight\",\n",
              " \"[Mitsuha] the nucleus it's movie to the comet will be kindon for whoch i've been acting away\",\n",
              " '[Taki] a fragment to the comet testrird a town that disaster',\n",
              " 'wait won uh huh huh',\n",
              " \"oh i can't it it it you can bake\",\n",
              " '[Taki] i gotta go peep',\n",
              " '[Taki] also sis did',\n",
              " '[Yotsuha] and you have a move',\n",
              " '[Mitsuha] this is two linessof like me broke a look leave it with you',\n",
              " \"[Tsukasa] that bad run there's a right\",\n",
              " '[Tsukasa] uh',\n",
              " '[Okudera] have it drew nees',\n",
              " '[Mitsuha] and agh',\n",
              " \"[Okudera] i had feelin' s firm you know\",\n",
              " 'ha gaer the pretty could have predicted me',\n",
              " 'and going to tokyo your own saya',\n",
              " '[Taki] who was it ago',\n",
              " \"[Grandma] you're dreaming nightnow until uh\",\n",
              " \"[Teshi] forget that's stay lather little cafe\",\n",
              " '[Taki] huhah',\n",
              " \"[Mitsuha] i can't you wildfire from\",\n",
              " \"[Taki] it's coming\",\n",
              " \"[Grandma] like s the most if it's him about this\",\n",
              " '[Saya] oh cause so hahahahaha',\n",
              " '[Taki] the weere everyone world',\n",
              " '[Taki] so why does sudden car stay',\n",
              " \"[Mitsuha] i fest so so uh he w'll be in ms insidents were as upprice\",\n",
              " '[Teshi] they mitsuha',\n",
              " '[Sara] even forehang',\n",
              " \"[Mitsuha] it does a matter is no way i'm going at the move y\",\n",
              " 'saya serious tomorrow uh',\n",
              " '[Taki] so that we ough forget things when we wake up',\n",
              " '[Taki] what do you',\n",
              " \"[Teshi] you're late kindof lost on eorremottyo\",\n",
              " \"a don't do what doing\",\n",
              " \"see this does a look right the two pm it's in agh\",\n",
              " '[Taki] do thiy just make it',\n",
              " '[Taki] uh ah',\n",
              " \"[Yotsuha] you sure does like you don't be if\",\n",
              " \"[Taki] the arching's of everyone who spoker\",\n",
              " '[Taki] even tokyo it might vanishi too undated',\n",
              " '[Tsukasa] i do what',\n",
              " '[Okudera] i have forget no one',\n",
              " \"[Taki] yes of course to me ng that's the place it's not bare right\",\n",
              " 'listen something out on the town were your soup over',\n",
              " \"[Mitsuha] that it's so co no\",\n",
              " '[Taki] i came th save her',\n",
              " '[Mitsuha] get',\n",
              " '[Teshi] but i rest taki sound thing',\n",
              " '[Teacher] no no bobyct i jobi argued it about',\n",
              " '[Grandma] could she come he sake de',\n",
              " \"[Mitsuha] what i'm no iim\",\n",
              " '[Okudera] he nots one bonning taki',\n",
              " \"[Okudera] it looks like that day who this thing date is begin' festival\",\n",
              " \"[Teacher] when about it between world's born\",\n",
              " '[Taki] oow you come to see',\n",
              " '[Mitsuha] tah',\n",
              " '[Teshi] but it was just the one time just the one time',\n",
              " '[Taki] ah',\n",
              " '[Taki] ah',\n",
              " '[Teshi] the',\n",
              " '[Okudera] no no boobbe counting on you then you know',\n",
              " \"[Taki] don't convey you dork he are you gard\",\n",
              " '[Teshi] we ould stop breaking the trudelater or the works okudera for severely rice and i',\n",
              " \"[Taki] weggled st water bride spirits sports and the comes approach to fare it's you you\",\n",
              " '[Taki] whis is the ne',\n",
              " \"[Grandma] you're not mixiuh y maybe what do you jupit my uh have to\",\n",
              " \"[Mitsuha] she's ham\",\n",
              " \"[Taki] who's thinit\",\n",
              " \"that we can stay where you leave switched its going to be heavy was how's outside with grandma\",\n",
              " '[Taki] was like',\n",
              " \"we're not on my trancts today\",\n",
              " '[Yotsuha] wha i know',\n",
              " '[Mitsuha] mitsuha',\n",
              " '[Taki] and be broke to taki ce',\n",
              " \"[Grandma] we band of your beshing told pretty leave in this hoff we're bad at nothing he cawer texts\",\n",
              " \"[Mitsuha] why i couldn't dell like that huh\",\n",
              " '[Mitsuha] dinnet',\n",
              " '[Teshi] yeah i ha',\n",
              " 'hey we oughtang now',\n",
              " \"[Grandma] that we're in hundred yeah the times\",\n",
              " '[Taki] wait are',\n",
              " \"to what's the kickbach of taki shoulds\",\n",
              " '[Okudera+Taki] mayugoro y the  yes and every earth stand trudy',\n",
              " '[Taki] no miss in your mayor s',\n",
              " '[Teshi] somehone',\n",
              " \"[Sara] it won't help\",\n",
              " \"[Grandma] miyamizu talkin' area magic hour\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}